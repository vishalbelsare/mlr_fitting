{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlrfit as mf\n",
    "import numba as nb\n",
    "\n",
    "from scipy.linalg import block_diag  \n",
    "from mlrfit import frob_loss, rel_diff, diag_sparseBCt, LinOpResidualMatrix, compute_perm_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_level_factor_fit(R, ranks, hpart, level, symm=False, PSD=False):\n",
    "    \"\"\"\n",
    "    Return updated block diagonal, where each block is BCt\n",
    "    delta_rm1[level]: scores for decreasing a rank by 1\n",
    "    delta_rp1[level]: scores for increasing a rank by 1\n",
    "    \"\"\"\n",
    "    dim = ranks[level]\n",
    "    num_blocks = len(hpart['rows']['lk'][level])-1\n",
    "    r1, c1 = 0, 0\n",
    "    m, n = hpart['rows']['lk'][0][-1], hpart['cols']['lk'][0][-1]\n",
    "    A_level = np.zeros((m, n))\n",
    "    for block in range(num_blocks):\n",
    "        r1, r2 = hpart['rows']['lk'][level][block], hpart['rows']['lk'][level][block+1]\n",
    "        c1, c2 = hpart['cols']['lk'][level][block], hpart['cols']['lk'][level][block+1]\n",
    "        if PSD:\n",
    "            assert r1==c1 and r2==c2\n",
    "            U, sigmas = mf.frob_low_rank_psd(R[r1:r2, c1:c2], dim = dim+1)\n",
    "            Vt = U.T\n",
    "        else:\n",
    "            U, Vt, sigmas = mf.frob_low_rank(R[r1:r2, c1:c2], dim = dim+1, symm=symm)\n",
    "        max_rank_block = min(r2-r1, c2-c1)\n",
    "        # print(sigmas)\n",
    "        if max_rank_block-1 >= dim >= 1 and sigmas.size >= dim+1:\n",
    "            A_level[r1:r2, c1:c2] = U[:, :-1] @ np.diag(sigmas[:-1]) @ Vt[:-1, :] \n",
    "        elif dim >= max_rank_block or sigmas.size <= dim:\n",
    "            A_level[r1:r2, c1:c2] = U @ np.diag(sigmas) @ Vt\n",
    "        r1 = r2; c1 = c2 \n",
    "    return A_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 122.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 155.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED low rank implementation tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED single_level_factor_fit implementation tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/parshakova.tanya/Documents/projects/MLR_Matrices/mlr_fitting/mlrfit/utils.py:409: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 2, 'A', False, aligned=True), Array(float64, 2, 'A', False, aligned=True))\n",
      "  hat_A_except_level[r1:r2, c1:c2] += np.dot(B_level[r1:r2], C_level[c1:c2].T)\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED factor_fit implementation tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "m, n  = 100, 75\n",
    "dim = 10\n",
    "\n",
    "# Test low rank implementation\n",
    "for _ in tqdm(range(M)):\n",
    "    A = np.random.randn(m, n)*10\n",
    "    U2, Vt2, sigmas2 = mf.frob_low_rank(A, dim=min(m,n))\n",
    "    mf.test_eigsh_svds(U2, sigmas2, Vt2, min(m,n), A, mode='svds')\n",
    "    assert (np.diff(sigmas2) <= 1e-9).all() and (sigmas2 == np.sort(sigmas2)[::-1]).all()\n",
    "    assert np.allclose(U2 @ np.diag(sigmas2) @ Vt2, A)\n",
    "\n",
    "for _ in tqdm(range(M)):\n",
    "    A = np.random.randn(m, n)*10\n",
    "    U2, Vt2, sigmas2 = mf.frob_low_rank(A, dim=dim)\n",
    "    mf.test_eigsh_svds(U2, sigmas2, Vt2, dim, A, mode='svds')\n",
    "    assert (np.diff(sigmas2) <= 1e-9).all() and (sigmas2 == np.sort(sigmas2)[::-1]).all()\n",
    "\n",
    "print(\"PASSED low rank implementation tests\")\n",
    "\n",
    "\n",
    "# Test low rank and single level fit implementation\n",
    "hpart = mf.random_hpartition(m,  n)\n",
    "mf.test_hpartition(hpart, m, n)\n",
    "num_levels = len(hpart[\"cols\"][\"lk\"])\n",
    "hat_A = mf.MLRMatrix(hpart=hpart, debug=True)\n",
    "\n",
    "for _ in tqdm(range(M)):\n",
    "    ranks = np.random.randint(1, min(m,n), num_levels)\n",
    "    R = np.random.randn(m,n)\n",
    "    for level in range(num_levels):\n",
    "        B_level, C_level, delta_rm1, delta_rp1, b_level, c_level = mf.single_level_factor_fit(R, ranks, hpart, \\\n",
    "                                                        level)\n",
    "        A_level = test_single_level_factor_fit(R, ranks, hpart, level)\n",
    "        assert (delta_rm1 + 1e-9 >= delta_rp1)\n",
    "        assert np.allclose(A_level, hat_A._block_diag_BCt(level, hpart, B_level, C_level))\n",
    "print(\"PASSED single_level_factor_fit implementation tests\")\n",
    "\n",
    "# Test low rank and block coordinate descent implementation\n",
    "hpart = mf.random_hpartition(m,  n)\n",
    "mf.test_hpartition(hpart, m, n)\n",
    "eps = 1e-2\n",
    "\n",
    "for _ in tqdm(range(5)):\n",
    "    ranks = np.random.randint(1, min(m,n), num_levels)\n",
    "    A = np.random.randn(m,n)\n",
    "    \n",
    "    cycle_size = 1 \n",
    "    losses = hat_A.factor_fit(A, ranks, hpart, eps_ff=eps, method='bcd',\\\n",
    "                                max_iters_ff=10**3, symm=False, warm_start=False)\n",
    "    for i in range(1, len(losses)-cycle_size):\n",
    "        assert losses[-i-cycle_size] - losses[-i] >= -1e-9, \\\n",
    "            print(f\"{i = }, {losses[-i-cycle_size] - losses[-i]}\", \\\n",
    "                \"loss is not decreasing with epochs\")\n",
    "    assert eps >= losses[-1-cycle_size] - losses[-1]\n",
    "    assert np.allclose(mf.rel_diff(hat_A.matrix(), den=A), losses[-1]),\\\n",
    "        print(mf.rel_diff(hat_A.matrix(), den=A), losses[-1])\n",
    "    \n",
    "    rows_lk = nb.typed.List(hpart['rows']['lk'])\n",
    "    cols_lk = nb.typed.List(hpart['cols']['lk'])\n",
    "    \n",
    "\n",
    "print(\"PASSED factor_fit implementation tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "ranks = np.array([10, 7, 5, 4, 1])\n",
    "ranks1 = ranks + 0\n",
    "ranks2 = ranks * 2\n",
    "n = 200\n",
    "\n",
    "pi_rows = np.random.permutation(n)\n",
    "hpart = {'rows':{'pi':pi_rows, 'lk':[]}, 'cols':{'pi':pi_rows, 'lk':[]}} \n",
    "for ngroups in [2, 5, 9, 17, n+1]:\n",
    "       hpart['rows']['lk'] += [ np.linspace(0, n, ngroups, endpoint=True, dtype=int)]\n",
    "hpart['rows']['lk'][1] = np.delete(hpart['rows']['lk'][1], -2)\n",
    "hpart['rows']['lk'][2] = np.delete(hpart['rows']['lk'][2], -4)\n",
    "hpart['cols']['lk'] = hpart['rows']['lk']\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    B1, C1 = np.random.randn(n, ranks1.sum()), np.random.randn(n, ranks1.sum())\n",
    "    B2, C2 = np.random.randn(n, ranks2.sum()), np.random.randn(n, ranks2.sum())\n",
    "\n",
    "    mlr1 = mf.MLRMatrix(B=B1, C=C1, hpart=hpart, ranks=ranks1)\n",
    "    mlr1.construct_sparse_format()\n",
    "\n",
    "    mlr2 = mf.MLRMatrix(B=B2, C=C2, hpart=hpart, ranks=ranks2)\n",
    "    mlr2.construct_sparse_format()\n",
    "    \n",
    "    B, C, ranks = mf.mlr_mlr_symm_hpar_matmul(B1, C1, ranks1, B2, C2, ranks2, hpart[\"rows\"][\"lk\"])\n",
    "\n",
    "    true_AA_p = mlr1.matrix() @ mlr2.matrix()\n",
    "    mlr_prod = mf.MLRMatrix(B=B, C=C, hpart=hpart, ranks=ranks)\n",
    "\n",
    "    assert np.allclose(true_AA_p, mlr_prod.matrix())\n",
    "    assert np.allclose(np.diag(true_AA_p), diag_sparseBCt(B, C, hpart['rows']['lk'], ranks)[mlr_prod.pi_inv_rows])\n",
    "\n",
    "print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED frob_loss, matmul and diag_sparseBCt\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    B1, C1 = np.random.randn(n, ranks1.sum()), np.random.randn(n, ranks1.sum())\n",
    "\n",
    "    mlr1 = mf.MLRMatrix(B=B1, C=C1, hpart=hpart, ranks=ranks1)\n",
    "    mlr1.construct_sparse_format()\n",
    "\n",
    "    mlr2 = mf.MLRMatrix(B=C1, C=B1, hpart=hpart, ranks=ranks1)\n",
    "    mlr2.construct_sparse_format()\n",
    "    \n",
    "    B, C, ranks = mf.mlr_mlr_symm_hpar_matmul(B1, C1, ranks1, C1, B1, ranks1, hpart[\"rows\"][\"lk\"])\n",
    "\n",
    "    true_AA_p = mlr1.matrix() @ mlr2.matrix()\n",
    "    mlr_prod = mf.MLRMatrix(B=B, C=C, hpart=hpart, ranks=ranks)\n",
    "\n",
    "    assert np.allclose(true_AA_p, mlr_prod.matrix())\n",
    "    assert np.allclose(np.diag(true_AA_p), diag_sparseBCt(B, C, hpart['rows']['lk'], ranks)[mlr_prod.pi_inv_rows])\n",
    "\n",
    "    G = np.random.randn(n, n//2)\n",
    "    perm_A = G @ G.T\n",
    "    rows_lk = hpart['rows']['lk']\n",
    "    cols_lk = hpart['cols']['lk']\n",
    "\n",
    "    l1 = frob_loss(perm_A, B, C, rows_lk, cols_lk, ranks)\n",
    "    l2 = frob_loss((G, G), B, C, rows_lk, cols_lk, ranks)\n",
    "    assert np.allclose(l1, l2)\n",
    "\n",
    "print(\"PASSED frob_loss, matmul and diag_sparseBCt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:43<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED compute_perm_residual implementation tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n  = 300\n",
    "dim = 10\n",
    "\n",
    "# Test low rank and single level fit implementation\n",
    "hpart = mf.random_hpartition(n,  n, symm=True)\n",
    "mf.test_hpartition(hpart, n, n)\n",
    "num_levels = len(hpart['rows']['lk']) \n",
    "hat_A = mf.MLRMatrix(hpart=hpart, debug=True)\n",
    "rows_lk = hpart['rows']['lk']\n",
    "cols_lk = hpart['cols']['lk']\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    for PSD in [True, False]:\n",
    "        ranks = np.random.randint(1, n//3, num_levels)\n",
    "        ranks[-1] = 1\n",
    "        G = np.random.randn(n, n//3)\n",
    "        perm_A = G @ G.T\n",
    "        B, C = np.random.randn(n, ranks.sum()), np.random.randn(n, ranks.sum())\n",
    "        if PSD: C = B\n",
    "\n",
    "        l1 = frob_loss(perm_A, B, C, rows_lk, cols_lk, ranks)\n",
    "        l2 = frob_loss((G, G), B, C, rows_lk, cols_lk, ranks)\n",
    "        assert np.allclose(l1, l2)\n",
    "        \n",
    "        levels = np.concatenate([np.arange(num_levels), np.arange(num_levels-1)[::-1]], axis=0)\n",
    "        for level in levels:\n",
    "            R = compute_perm_residual(perm_A, B, C, level, rows_lk, cols_lk, ranks)\n",
    "            R2 = compute_perm_residual((G, G), B, C, level, rows_lk, cols_lk, ranks)\n",
    "            assert np.allclose(R, R2.toarray()), print(rel_diff(R, R2.toarray()))\n",
    "            B_level, C_level, delta_rm1, delta_rp1, b_level, c_level = mf.single_level_factor_fit(R, ranks, hpart, \\\n",
    "                                                            level, PSD=PSD)\n",
    "            A_level = test_single_level_factor_fit(R, ranks, hpart, level, PSD=PSD)\n",
    "            assert (delta_rm1 + 1e-9 >= delta_rp1)\n",
    "            assert np.allclose(A_level, hat_A._block_diag_BCt(level, hpart, B_level, C_level))\n",
    "            # A_level = hat_A._block_diag_BCt(level, hpart, B_level, C_level)\n",
    "            B_level, C_level, delta_rm1, delta_rp1, b_level, c_level = mf.single_level_factor_fit(R2, ranks, hpart, \\\n",
    "                                                            level, PSD=PSD)\n",
    "            assert (delta_rm1 + 1e-9 >= delta_rp1)\n",
    "            assert np.allclose(A_level, hat_A._block_diag_BCt(level, hpart, B_level, C_level))\n",
    "\n",
    "print(\"PASSED compute_perm_residual implementation tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED compute_perm_residual implementation tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m, n  = 150, 100\n",
    "dim = 10\n",
    "PSD = False\n",
    "\n",
    "# Test low rank and single level fit implementation\n",
    "hpart = mf.random_hpartition(m,  n)\n",
    "mf.test_hpartition(hpart, m, n)\n",
    "num_levels = len(hpart['rows']['lk']) \n",
    "hat_A = mf.MLRMatrix(hpart=hpart, debug=True)\n",
    "rows_lk = hpart['rows']['lk']\n",
    "cols_lk = hpart['cols']['lk']\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    ranks = np.random.randint(1, n//2, num_levels)\n",
    "    ranks[-1] = 1\n",
    "    G1 = np.random.randn(m, n//3)\n",
    "    G2 = np.random.randn(n, n//3)\n",
    "    perm_A = G1 @ G2.T\n",
    "    B, C = np.random.randn(m, ranks.sum()), np.random.randn(n, ranks.sum())\n",
    "    \n",
    "    levels = np.concatenate([np.arange(num_levels), np.arange(num_levels-1)[::-1]], axis=0)\n",
    "    for level in levels:\n",
    "        R = compute_perm_residual(perm_A, B, C, level, rows_lk, cols_lk, ranks)\n",
    "        R2 = compute_perm_residual((G1, G2), B, C, level, rows_lk, cols_lk, ranks)\n",
    "        assert np.allclose(R, R2.toarray()), print(rel_diff(R, R2.toarray()))\n",
    "        B_level, C_level, delta_rm1, delta_rp1, b_level, c_level = mf.single_level_factor_fit(R, ranks, hpart, \\\n",
    "                                                        level, PSD=PSD)\n",
    "        A_level = test_single_level_factor_fit(R, ranks, hpart, level, PSD=PSD)\n",
    "        assert (delta_rm1 + 1e-9 >= delta_rp1)\n",
    "        assert np.allclose(A_level, hat_A._block_diag_BCt(level, hpart, B_level, C_level))\n",
    "        B_level, C_level, delta_rm1, delta_rp1, b_level, c_level = mf.single_level_factor_fit(R2, ranks, hpart, \\\n",
    "                                                        level, PSD=PSD)\n",
    "        assert (delta_rm1 + 1e-9 >= delta_rp1)\n",
    "        assert np.allclose(A_level, hat_A._block_diag_BCt(level, hpart, B_level, C_level))\n",
    "\n",
    "print(\"PASSED compute_perm_residual implementation tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilevel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
